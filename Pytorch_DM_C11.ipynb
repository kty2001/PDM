{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEacanZk7clXdpa0AX9ZaG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 11장 - 종양 탐지를 위한 분류 모델 훈련"],"metadata":{"id":"YEDPBc4yMYM-"}},{"cell_type":"markdown","source":["## 1절 - 기본 모델과 훈련 루프"],"metadata":{"id":"XG8Ot1TrMojt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"no7g9IdUHwbd"},"outputs":[],"source":["# 2부의 나머지 부분에서 더 큰 프로젝트에 필요한 도구가 될 분류 모델과 훈련 루프 만들 예정\n","# 이를 위해 Ct 클래스와 LunaDataset 클래스를 DataLoader 인스턴스에 삽입\n","# 이후 인스턴스를 데이터와 함께 훈련 루프와 검증 루프를 거쳐 분류 모델에 입력"]},{"cell_type":"code","source":["# 다음으로 훈련 루프 실행 결과를 사용하기 위해 여러 제약 있는 데이터를 어떻게 고품질의 결과로 만드는지 설명\n","# 이후 장에서는 데이터의 제약 사항 완화할 방안 확인"],"metadata":{"id":"MAhkiauVNHgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 후보는 결절인지 아닌지로 분류하며, 모델에 전달할 각 샘플에 대해 종류별로 레이블 할당해야 함\n","# 각 샘플에 있는 후보에 '결절' 혹은 '비결절' 레이블 매겨짐"],"metadata":{"id":"OPkJiUfjNZ9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 시작부터 끝까지 연결된 엔드투엔드 파이프라인을 초기에 만들어 놓으면 좋은 이정표가 됨\n","# 결과를 분석적으로 평가할 수 있을 만큼 잘 작동한다면, 매번 변경으로 결과가 향상된다는 확신을 가질 수 있음\n","# 적어도 효과 없는 변경이나 실험은 차선으로 미룰 수 있음"],"metadata":{"id":"0uEDlkxpNtPy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 구현의 기본 구조\n","# 모델 초기화 및 데이터 로딩\n","# 임의로 선택한 에포크 수로 루프 반복\n","#   - LunaDataset이 반환한 훈련 데이터의 배치 루프 돌기\n","#   - 백그라운드에서 데이터로도 워커 프로세스를 적합한 배치 읽어들이기\n","#   - 배치를 분류 모델에 전달해 결과 얻기\n","#   - 추정 결과를 실측 데이터와 비교하여 손실 계산\n","#   - 임시 데이터 구조에 모델의 성능 메트릭 기록\n","#   - 오차 역전파로 모델 가중치 조정\n","#   - 검증 데이터 배치로 루프 반복\n","#   - 백그라운드 워커 프로세스에서 검증 데이터 배치 읽어들이기\n","#   - 배치 분류하고 손실 계산\n","#   - 모델이 검증 데이터에 대해 얼마나 잘 동작했는지 기록\n","#   - 매 에포크마다 진행 상황과 성능 정보 출력"],"metadata":{"id":"ZnynXBOzOCn6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 전보다 복잡해진 만큼 구조적으로 프로그램 작성해야 함\n","# 프로젝트는 잘 만들어진 여러 함수를 훈련 애플리케이션에서 사용하며, 데이터셋 등을 위한 코드는 자체적인 파이썬 모듈로 분리"],"metadata":{"id":"-cSz-ni3O860"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 자신의 프로젝트 수행할 때는 복잡도에 어울리는 구조나 설계 수준 택해야 함\n","# 충분한 구조화 없으면 실험을 깔끔하게 수행하거나 문제 해결하기 어려우며, 자신이 무엇을 하는지 설명하기도 쉽지 않음\n","# 과한 구조화는 쓸모없는 인프라 구조 작성에 시간을 낭비하게 만들며, 그 틀에 맞추기 위한 여러 작업을 하느라 진행이 더딜 것임"],"metadata":{"id":"XCUd2itYPLbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 진척에 대한 다양한 메트릭 수집할 것임\n","# 조흥 메트리 로깅 없이 훈련에 준 변화가 어떤 영향을 미치는지 파악하기 어려움\n","# 올바른 메트릭 수집하는 것의 중요성 이야기 할 것\n","# 메트릭을 수집하기 위한 인프라 구조 깔고 전체와 개별 클래스 단위로 손실값과 잘 분류된 샘플의 백분율을 수집하고 표시할 것임"],"metadata":{"id":"HdPy_H5aPp3t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2절 - 애플리케이션의 메인 진입점"],"metadata":{"id":"FxQIAn7QQEgC"}},{"cell_type":"code","source":["# 2부는 완전한 명령행 애플리케이션임\n","# 명령행 인자를 파싱하고 완전한 --help 옵션 제공해 여러 환경에서 쉽게 실행 가능"],"metadata":{"id":"UuZ99HKPQEEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 애플리케이션은 클래스로 구현해 필요할 때 인스턴스로 만들어 실행함\n","# 운영체제 수준에서 별도 프로세스로 띄우지 않아도 애플리케이션 구동 가능"],"metadata":{"id":"k3zzek9jQUC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 함수 호출이나 OS 레벨의 프로세스로 훈련 구동 가능하면 함수 호출을 래핑해 주피터 노트북에 넣을 수 있으므로 코드를 쉽게 네이티브 CLI나 브라우저에서 호출할 수 있는 장점 존재"],"metadata":{"id":"jDVJn37OQiMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# code/p2_run_everything.ipynb\n","def run(app, *argv):\n","    argv = list(argv)\n","    argv.insert(0, '--num-workers=4')  # <1>\n","    log.info(\"Running: {}({!r}).main()\".format(app, argv))\n","\n","    app_cls = importstr(*app.rsplit('.', 1))  # <2>\n","    app_cls(argv).main()\n","\n","    log.info(\"Finished: {}.{!r}).main()\".format(app, argv))"],"metadata":{"id":"HW_asqlhSVCh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 파일 끝부분에 애플리케이션 객체를 인스턴스로 만들고 main 메소드를 호출하는 표준 형태의 if main 코드 확인 가능"],"metadata":{"id":"0hwCLakpSha2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:386\n","if __name__ == '__main__':\n","    LunaTrainingApp().main()"],"metadata":{"id":"lFQaeZRHSef-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 처음의 애플리케이션 클래스를 보면 위에서 호출한 두 함수 __init__과 main 볼 수 있음\n","# 명령행 인자를 받으므로 애플리케이션 __init__ 함수에서 표준 argparse 라이브러리를 사용\n","# 초기화 함수에 커스텀 인자를 전달하 수 있어야만 함\n","# main 메소드는 애플리케이션의 핵심 로직을 위한 진입점임"],"metadata":{"id":"sg7mvZ97QtqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:31\n","class LunaTrainingApp:\n","    def __init__(self, sys_argv=None):\n","        if sys_argv is None:\n","            sys_argv = sys.argv[1:]\n","\n","        parser = argparse.ArgumentParser()\n","        parser.add_argument('--num-workers',\n","            help='Number of worker processes for background data loading',\n","            default=8,\n","            type=int,\n","        )\n","\n","        # 63행\n","        self.cli_args = parser.parse_args(sys_argv)\n","        self.time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H.%M.%S')\n","\n","        # 137행\n","        def main(self):\n","            log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))"],"metadata":{"id":"jD1PGvMjSsEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 매우 일반적인 구조이므로 향후 다른 프로젝트에서 재사용 가능\n","# __init__ 안에서의 인자 파싱은 애플리케이션 호출에 영향 받지 않고 설정 가능"],"metadata":{"id":"m7YElN01RpxO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3절 - 사전 훈련 설정과 초기화"],"metadata":{"id":"gs_6XdP-TAIv"}},{"cell_type":"code","source":["# 에포크 내의 각 배치 순회하기 전 초기화가 필요\n","# 모델과 옵티마이저의 초기화와 Dataset과 DataLoader 인스턴스 초기화로 나눌 수 있음\n","# LunaDataset은 랜덤으로 선택한 샘플셋을 정의해 훈련 에포크 채울 것이고 DataLoader 인스턴스는 데이터셋으로부터 데이터를 읽는 작업 수행하여 애플리케이션에 제공"],"metadata":{"id":"wHUXuHxGSi4Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .1 모델과 옵티마이저 초기화"],"metadata":{"id":"xEszb9IdXFy9"}},{"cell_type":"code","source":["# 이번 절에서는 LunaModel 세부를 블랙박스로 생각\n","# 시작 부분 확인"],"metadata":{"id":"zrwRFbkVXEd4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:31\n","class LunaTrainingApp:\n","    def __init__(self, sys_argv=None):\n","\n","        # 70행\n","        self.use_cuda = torch.cuda.is_available()\n","        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n","\n","        self.model = self.initModel()\n","        self.optimizer = self.initOptimizer()\n","\n","    def initModel(self):\n","        model = LunaModel()\n","        if self.use_cuda:\n","            log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n","            if torch.cuda.device_count() > 1: # 복수의 GPU 탐지\n","                model = nn.DataParallel(model) # 모델 래핑\n","            model = model.to(self.device) # GPU에 모델 파라미터 전달\n","        return model\n","\n","    def initOptimizer(self):\n","        return SGD(self.model.parameters(), lr=0.001, momentum=0.99)"],"metadata":{"id":"DDc8lNEpXhSu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 복수의 GPU 사용시 nn.DataParallel 클래스 사용해 모든 GPU에 작업을 분산하여 처리 후 파라미터를 모아 조정 작업을 재동기화하는 방식으로 진행됨"],"metadata":{"id":"y4OSUGRlXwvd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# self.use_cuda값이 True면 self.model.to(device) 호출로 모델 파라미터를 GPU로 옮기고 컨볼루션과 숫자 연산에 GPU 사용하도록 설정\n","# 옵티마이저 구성 전에 설정하지 않는다면 옵티마이저는 CPU 상의 파라미터 객체를 봄"],"metadata":{"id":"5MgQVSfOYOQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모멘텀과 함께 SGD 사용\n","# SGD는 대부분의 문제에 적용가능하며, lr=0.001과 momentum=0.99도 안전한 선택에 해당하는 값임\n","# 잘 안되면 lr을 0.1이나 0.0001로 변경해볼만 함"],"metadata":{"id":"IaE7ImI9YllB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. 데이터 로더의 관리와 데이터 공급"],"metadata":{"id":"YZ-ttLDTbqfD"}},{"cell_type":"code","source":["# LunaDataset 클래스는 원본 데이터와 파이토치 빌딩 블럭을 위한 구조화된 텐서 사이의 가교 역할\n","# LunaDataet.__getitem__에 있던 ct_t.unsqueeze(0)는 데이터의 네 번째 차원인 채널을 제공함\n","# 단일한 밀도를 가지므로 채널 차원 크기는 1"],"metadata":{"id":"kS3n2l9OZCnC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 단일 샘플에 대한 훈련이나 검증 작업 수행은 대부분의 플랫폼에서 이미 여러 샘플에 대한 병렬 계산을 지원하기 때문에 컴퓨터 자원을 비효율적으로 사용함\n","# 개선을 위해 여러 셈플을 배치 튜플로 묶어 한 번에 처리될 수 있게 해야 함\n","# 5차원(N)을 동일한 배치 내에서 샘플을 구별하는 용도로 사용"],"metadata":{"id":"oFhS4pwmcc9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DataLoader 클래스가 배치를 구현하였고 CT 스캔을 텐서로 바꾸기 위해 LunaDataset 클래스를 만들었으니 데이터셋을 데이터 로더에 연결하면 됨"],"metadata":{"id":"uMSBvtjzdAX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:89\n","    def initTrainDl(self):\n","        train_ds = LunaDataset( # 커스텀 데이터셋\n","            val_stride=10,\n","            isValSet_bool=False,\n","        )\n","\n","        batch_size = self.cli_args.batch_size\n","        if self.use_cuda:\n","            batch_size *= torch.cuda.device_count()\n","\n","        train_dl = DataLoader( # 바로 사용하면 되는 클래스\n","            train_ds,\n","            batch_size=batch_size, # 자동으로 배치로 나뉨\n","            num_workers=self.cli_args.num_workers,\n","            pin_memory=self.use_cuda, # 고정된 메모리 영역이 GPU로 빠르게 전송됨\n","        )\n","\n","        return train_dl\n","\n","    # 137행\n","    def main(self):\n","        log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n","\n","        train_dl = self.initTrainDl()\n","        val_dl = self.initValDl() # 검증 데이터 로더는 훈련 데이터 로더와 유사"],"metadata":{"id":"21-mXkSfdSn-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 로더는 개별 샘플을 배치로 만들고, 별도의 프로세스와 공유 메모리를 사용한 병렬 로딩도 제공\n","# 데이터 로더 인스턴스 만들 때 num_workers=만 지정하면 나머지 알아서 처리되고 각 워커 프로세스는 배치 생성함"],"metadata":{"id":"uJvZP3y5eb22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 코드에서 for batch_tup in self.train_dl: 처럼 루프 돌 때 매번 Ct를 로드하고 샘플을 가져와 배치할 때까지 기다릴 필요 없음\n","# 이미 로딩 끝난 batch_tup을 바로 사용하며 워커 프로세스는 다음 순회 시 사용하기 위한 또 다른 배치를 로드하기 위해 자동으로 해제될 것\n","# 파이토치 데이터 로딩 기능 사용 시 GPU 계산과 데이터 로딩을 동시에 진행하므로 대부분의 경우 프로젝트 빠르게 실행 가능"],"metadata":{"id":"yRLXz0hKe_mh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4절 - 첫 번째 경로 신경망 설계"],"metadata":{"id":"rMH3KOFofkZC"}},{"cell_type":"markdown","source":["#### .1 핵심 컨볼루션"],"metadata":{"id":"1qlbu9YkjLDV"}},{"cell_type":"code","source":["# 분류 모델에서는 테일, 백본(=바디), 헤드로 구성된 구조가 흔함\n","# 테일(tail)은 입력을 신경망에 넣기 전 처리 과정을 담당하는 제일 첫 부분의 일부 계층\n","# 백본이 원하는 형태로 입력을 만들어야 하므로 신경망의 나머지 부분과는 구조나 구성이 다른 경우가 많음\n","# 우리는 단순 배치 정규화 계층 사용"],"metadata":{"id":"1bQY7d11fkRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 백본은 여러 계층을 가지는데 일반적으로 연속된 블럭에 배치됨\n","# 각 블럭은 동일한 세트의 계층을 가지며 블럭을 거칠 때마다 필요한 입력 크기나 필터 수가 달라짐\n","# 우리는 두 개의 3*3 컨볼루션과 하나의 활성함수, 맥스 풀링 연산이 이어진 블럭 사용"],"metadata":{"id":"tySYj968jqsB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 블럭 코드 model.py:67\n","class LunaBlock(nn.Module):\n","    def __init__(self, in_channels, conv_channels):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv3d(\n","            in_channels, conv_channels, kernel_size=3, padding=1, bias=True,\n","        )\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv3d(\n","            conv_channels, conv_channels, kernel_size=3, padding=1, bias=True,\n","        )\n","        self.relu2 = nn.ReLU(inplace=True)\n","\n","        self.maxpool = nn.MaxPool3d(2, 2)\n","\n","    def forward(self, input_batch):\n","        block_out = self.conv1(input_batch)\n","        block_out = self.relu1(block_out)\n","        block_out = self.conv2(block_out)\n","        block_out = self.relu2(block_out)\n","\n","        return self.maxpool(block_out)"],"metadata":{"id":"pzTxdkBykE5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 헤드는 백본의 출력을 받아 원하는 출력 형태로 변환\n","# 컨볼루션 신경망에서 이 작업은 중간 출력물을 평탄화 하고 완전 연결 계층에 전달하는 역할을 하기도 함\n","# 우리의 분류는 두 가지뿐이므로 하나의 평탄화 계층만 사용"],"metadata":{"id":"eQROpjaXkefo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이 블럭에서는 3*3*3 컨볼루션 사용 -> 27개의 복셀이 입력되고 1개를 출력함\n","# 컨볼루션층이 쌓여 있어 마지막 출력 복셀은 커널의 크기보다 입력의 영향을 받음\n","# 두 데이터의 최종 출력은 실질적으로 5*5*5 수용 필드를 가져 조금 큰 하나의 컨볼루션층처럼 동작\n","# 결과적으로 두 층의 3*3*3 계층은 5*5*5 컨볼루션보다 적은 파리미터를 가지고 계산이 더 빠름"],"metadata":{"id":"VM0SVwSRk8W5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 두 층의 컨볼루션의 출력은 2*2*2 맥스 풀링으로 들어감\n","# 6*6*6 수용 필드에서 7/8에 해당하는 데이터 버리고 가장 큰 값 가지는 한 개의 5*5*5필드 생성하는 것임\n","# 버려지는 입력 복셀도 맥스 풀링을 통해 출력 픽셀 하나에 대해 결국은 중첩되는 입력 필드가 연결되므로 어떤 식으로든 최종 출력에 영향 줌"],"metadata":{"id":"5Z2MwCnAnbk8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 컨볼루션층을 통해 수용 필드가 줄어들지만 패딩을 사용하고 있어 입력과 출력 이미지 크기는 동일함"],"metadata":{"id":"txi5WZrioFf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 위 블록은 여러 번 반복하며 모델의 백본을 구성함"],"metadata":{"id":"bXNqGBvhoZRP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .2 전체 모델"],"metadata":{"id":"AMcbadbXod1U"}},{"cell_type":"code","source":["# model.py:13\n","class LunaModel(nn.Module):\n","    def __init__(self, in_channels=1, conv_channels=8):\n","        super().__init__()\n","\n","        # 테일\n","        self.tail_batchnorm = nn.BatchNorm3d(1)\n","\n","        # 백본\n","        self.block1 = LunaBlock(in_channels, conv_channels)\n","        self.block2 = LunaBlock(conv_channels, conv_channels * 2)\n","        self.block3 = LunaBlock(conv_channels * 2, conv_channels * 4)\n","        self.block4 = LunaBlock(conv_channels * 4, conv_channels * 8)\n","\n","        # 헤드\n","        self.head_linear = nn.Linear(1152, 2)\n","        self.head_softmax = nn.Softmax(dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"id":"T5ixEyd5odhV","executionInfo":{"status":"error","timestamp":1707377666552,"user_tz":-540,"elapsed":271,"user":{"displayName":"김태윤","userId":"12351183305385272389"}},"outputId":"153cf287-30fa-4963-9d19-dd240e11f74e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'nn' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-c297dbed7a55>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.py:13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLunaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}]},{"cell_type":"code","source":["# model.py:13\n","class LunaModel(nn.Module):\n","    def __init__(self, in_channels=1, conv_channels=8):\n","        super().__init__()\n","\n","        self.tail_batchnorm = nn.BatchNorm3d(1)\n","\n","        self.block1 = LunaBlock(in_channels, conv_channels)\n","        self.block2 = LunaBlock(conv_channels, conv_channels * 2)\n","        self.block3 = LunaBlock(conv_channels * 2, conv_channels * 4)\n","        self.block4 = LunaBlock(conv_channels * 4, conv_channels * 8)\n","\n","        self.head_linear = nn.Linear(1152, 2)\n","        self.head_softmax = nn.Softmax(dim=1)"],"metadata":{"id":"-ipSWcUUo6bt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테일은 nn.BatchNorm3d를 사용해 입력을 정규화 함\n","# nn.BatchNorm3d는 입력값을 이동시키고 비율을 조정해 평균이 0이고 표준 정규분포 1을 따르게 함\n","# 특이한 하운스필드 단위는 신경망 뒤에서는 보이지 않음\n","# 입력 단위를 알고 있고 관련 조직이 가져야 하는 값이 무엇인지 파악하고 있어 수정된 정규화를 손쉽게 구현 가능"],"metadata":{"id":"3pAFE6igmU6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 백본에는 4개의 반복 블럭이 있고 nn.Module 서브클래스를 각각 구분하여 사용\n","# 각 블럭은 2*2*2 맥스 풀링 연산으로 끝나므로 이미지는 16배 줄어든 형태가 나옴\n","# 32*48*48 이미지가 입력이었으므로 2*3*3이 됨"],"metadata":{"id":"OzfDOiXAm0VJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테일에는 완전 연결 계층 뒤로 nn.Softmax가 있음\n","# 소프트맥스는 단일 레이블 분류에서 유용한 함수\n","# 출력을 0~1 사이값으로 묶어서 입력의 절댓값이 커져도 영향받지 않으며 입력 내 상대적인 값에만 영향 받으므로 정답이 얼마나 확실한지 표현하기 좋음\n","# 모델에서는 파이토치 버전인 nn.Softmax를 사용해 배치나 텐서에 호환되고 자동미분도 빠르게 실행 가능"],"metadata":{"id":"x0XC3n1EnqhZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# self.block4의 출력을 완전 연결 계층에 넣지 못하는 문제 발생\n","# 출력은 샘플마다 2*3*3이미지에 64개 채널이지만 완전 연결 계층의 입력은 1차원 벡터"],"metadata":{"id":"-POUI26UoF8g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward 메소드 확인\n","# model.py:50\n","def forward(self, input_batch):\n","        bn_output = self.tail_batchnorm(input_batch)\n","\n","        block_out = self.block1(bn_output)\n","        block_out = self.block2(block_out)\n","        block_out = self.block3(block_out)\n","        block_out = self.block4(block_out)\n","\n","        conv_flat = block_out.view(\n","            block_out.size(0), # 배치 크기\n","            -1,\n","        )\n","        linear_output = self.head_linear(conv_flat)\n","\n","        return linear_output, self.head_softmax(linear_output)"],"metadata":{"id":"mrjU0UQ8MwV7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# view 함수를 이용해 평탄화 수행 후 데이터 전달\n","# 연산은 동작에 영향 미치는 파라미터 저장을 요구하지 않으므로 forward 함수 내에서 연산 실행\n","# 컨볼루션 사용해 분류나 회귀 혹은 이미지가 아닌 출력 결과를 만드는 대부분의 모델은 신경망의 헤드에 유사한 요소 가짐"],"metadata":{"id":"WMHhu9NsM-Qi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward 메소드는 출력을 위해 logit과 소프트맥스로 확률 만듦\n","# logit은 소프트맥스 계층에 들어가기 전의 입력임\n","# 훈련 중에는 nn.CrossEntropyLoss 계산을 위해 로지트 값을 사용하며 실제 분류할 때는 확률값 사용\n","# 소프트맥스처럼 상태값이 따로 없고 두 값의 차이가 단순한 경우에는 훈련 때와 실제 제품으로 사용할 때가 다른 경우 많음"],"metadata":{"id":"Q5YDpnbgNcjL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델이 좋은 성능 낼 수 있도록 동작하려면 모델의 가중치, 편향값, 여러 파라미터가 특정 속성을 드러내야 함\n","# 여러 정규화 기술로 계층의 출력을 잘 동작하게 만들기도 하지만 신경망 가중치 초기화가 가장 단순한 방법\n","# 파이토치는 초기화를 보완하는 수단을 제공하지 않으므로 직접 해야 함"],"metadata":{"id":"Vvo9Imv3OSVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# _init_weights 함수를 기본으로 사용 가능\n","# model.py:30\n","def _init_weights(self):\n","    for m in self.modules():\n","        if type(m) in {\n","            nn.Linear,\n","            nn.Conv3d,\n","            nn.Conv2d,\n","            nn.ConvTranspose2d,\n","            nn.ConvTranspose3d,\n","        }:\n","            nn.init.kaiming_normal_(\n","                m.weight.data, a=0, mode='fan_out', nonlinearity='relu',\n","            )\n","            if m.bias is not None:\n","                fan_in, fan_out = \\\n","                    nn.init._calculate_fan_in_and_fan_out(m.weight.data)\n","                bound = 1 / math.sqrt(fan_out)\n","                nn.init.normal_(m.bias, -bound, bound)"],"metadata":{"id":"AGYDlq4DOz3T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5절 - 모델 훈련과 검증"],"metadata":{"id":"LfuXoOXFPtY_"}},{"cell_type":"code","source":["# 훈련 루프 코드\n","# training.py:137\n","def main(self):\n","\n","    # 143행\n","    for epoch_ndx in range(1, self.cli_args.epochs + 1):\n","        trnMetrics_t = self.doTraining(epoch_ndx, train_dl)\n","        self.logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n","\n","    # 165행\n","def doTraining(self, epoch_ndx, train_dl):\n","        self.model.train()\n","        trnMetrics_g = torch.zeros( # 빈 메트릭 배열 초기화\n","            METRICS_SIZE,\n","            len(train_dl.dataset),\n","            device=self.device,\n","        )\n","\n","        batch_iter = enumerateWithEstimate(\n","            train_dl,\n","            \"E{} Training\".format(epoch_ndx),\n","            start_ndx=train_dl.num_workers,\n","        )\n","        for batch_ndx, batch_tup in batch_iter:\n","            self.optimizer.zero_grad() # 남은 가중치 텐서 해제\n","\n","            loss_var = self.computeBatchLoss(\n","                batch_ndx,\n","                batch_tup,\n","                train_dl.batch_size,\n","                trnMetrics_g\n","            )\n","\n","            loss_var.backward() # 모델 가중치 조정\n","            self.optimizer.step()\n","\n","        self.totalTrainingSamples_count += len(train_dl.dataset)\n","\n","        return trnMetrics_g.to('cpu')"],"metadata":{"id":"vGs4Rw96PLZs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trnMetrics_g 텐서가 훈련 중 자세한 클래스 단위 메트릭 수집함\n","# 규모가 큰 프로젝트에서는 위 값으로 종요한 통찰 얻는 경우가 많기 때문에 필요\n","# 완료 시간 예측을 제공하기 위해 enumerateWithEstimate 사용\n","# 실제 손실 계산이 computeBatchLoss 메소드에서 이뤄지게 함으로써 코드를 재사용함"],"metadata":{"id":"5N6nviDNR2tH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trnMetics_g 텐서의 목적은 각 샘프레 대해 computeBatchLoss 함수부터 logMetrics 함수까지 어떻게 동작했는지에 대한 정보 전달하는 것"],"metadata":{"id":"xM2u6hoCVKsB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .1 computeBatchLoss 함수"],"metadata":{"id":"T0X4r4qYZlaY"}},{"cell_type":"code","source":["# computeBatchLoss 함수는 훈련 루프와 검증 루프 양쪽에서 호출됨\n","# 샘플 배치에 대해 손실을 계산하는 함수\n","# 부가적으로 각 샘플에 대해 모델이 만들어내는 출력에 대한 정보도 계산해서 기록하여, 각 클래스별로 계산이 얼마나 정확한지 백분율로 계산 가능하며 분류가 잘 되지 않는 클래스를 찾아 집중 개선 가능"],"metadata":{"id":"J1BhGS-SVlG5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# computeBatchLoss 함수의 핵심 기능은 배치 단위로 모델에 입력 넣고 손실을 계산하는 것이므로 CrossEntropyLoss 사용\n","# 배치 튜플의 패킹 풀고 텐서를 GPU로 옮긴 후 모델 호출하는 과정임"],"metadata":{"id":"ix3E0Ik2WIfO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:225\n","def computeBatchLoss(self, batch_ndx, batch_tup, batch_size, metrics_g):\n","    input_t, label_t, _series_list, _center_list = batch_tup\n","\n","    input_g = input_t.to(self.device, non_blocking=True)\n","    label_g = label_t.to(self.device, non_blocking=True)\n","\n","    logits_g, probability_g = self.model(input_g)\n","\n","    loss_func = nn.CrossEntropyLoss(reduction='none')\n","    loss_g = loss_func( # reduction='none'으로 샘플별 손실값 얻음\n","        logits_g,\n","        label_g[:,1], # 원핫 인코딩 클래스의 인덱스\n","    )\n","\n","    # 248행\n","    return loss_g.mean() # 샘플별 손실값을 단일값으로 합침"],"metadata":{"id":"b-J5-WhOWwNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 손실값이 들어있는 텐서를 샘플마다 얻어 개별 손실값 추적 가능하고 원하는 방식으로 병합 가능하게 함\n","# 위 코드에서는 각 샘플에 대한 손실 평균을 반환해 배치 단위의 손실과 동일한 값을 넘김\n","# 샘플별 통계값을 가질 필요없으면 배치 단위의 손실값 평균 계산 사용해도 문제 없음"],"metadata":{"id":"oHiGD-PTWziH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 역전파 단계 가기 전에 추후 분석을 위해 샘플별 통계값 기록\n","# training.py:26\n","METRICS_LABEL_NDX=0 # 인덱스를 위한 변수 선언은 모듈 범위에서 유효함\n","METRICS_PRED_NDX=1\n","METRICS_LOSS_NDX=2\n","METRICS_SIZE = 3\n","\n","# 225행\n","def computeBatchLoss(self, batch_ndx, batch_tup, batch_size, metrics_g):\n","    # 238행\n","    start_ndx = batch_ndx * batch_size\n","    end_ndx = start_ndx + label_t.size(0)\n","    # 기울기에 의존적인 메트릭 없으므로 detach 사용\n","    metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = \\\n","        label_g[:,1].detach()\n","    metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = \\\n","        probability_g[:,1].detach()\n","    metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = \\\n","        loss_g.detach()\n","\n","    return loss_g.mean()"],"metadata":{"id":"GlzrJNVXYLs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 훈련과 검증 샘플에 대해 레이블, 예측 결과, 손실값을 기록해 모델 동작 조사에 사용하기 위한 풍부한 세부 정보 확보함\n","# 클래스 단위의 통계를 모으기 위함과 이상하게 분류된 샘플을 찾아서 왜 그런지를 쉽게 확인하는데 사용"],"metadata":{"id":"e8FCDcykZFHS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .2 훈련 때와 유사한 검증 루프"],"metadata":{"id":"aDHUEheqZtr5"}},{"cell_type":"code","source":["# 검증 루프는 읽기 전용이라는 점과 손실값을 사용하지 않으며 가중치도 조정하지 않는다는 차이점을 가짐\n","# 모델에 대해 아무것도 바꾸면 안되며, with torch.no_grad() 콘텍스트 매니저가 명시적으로 기울기 계산이 불필요하다고 하므로 훈련 때보다 빠름"],"metadata":{"id":"d4cb0kNqZxm3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:137\n","def main(self):\n","    for epoch_ndx in range(1, self.cli_args.epochs + 1):\n","\n","        # 157행\n","        valMetrics_t = self.doValidation(epoch_ndx, val_dl)\n","        self.logMetrics(epoch_ndx, 'val', valMetrics_t)\n","\n","# 203행\n","def doValidation(self, epoch_ndx, val_dl):\n","    with torch.no_grad():\n","        self.model.eval()\n","        valMetrics_g = torch.zeros(\n","            METRICS_SIZE,\n","            len(val_dl.dataset),\n","            device=self.device,\n","        )\n","\n","        batch_iter = enumerateWithEstimate(\n","            val_dl,\n","            \"E{} Validation \".format(epoch_ndx),\n","            start_ndx=val_dl.num_workers,\n","        )\n","        for batch_ndx, batch_tup in batch_iter:\n","            self.computeBatchLoss(\n","                batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n","\n","    return valMetrics_g.to('cpu')"],"metadata":{"id":"4XtD7L0wdp5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 신경망 가중치 조정하지 않고 computeBatchLoss가 주는 손실값 사용하지 않고 옵티마이저 참조도 하지 않아 루프에는 computeBatchLoss 호출만 남음\n","# computBatchLoss 호출로 넘어오는 배치의 전체 손실값을 사용하지 않지만 호출의 부수효과로 valMetrics_g에 메트릭 계속 모음"],"metadata":{"id":"pHmWimJfeYEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6절 - 성능 메트릭 출력"],"metadata":{"id":"lipKQWfre515"}},{"cell_type":"code","source":["# 에포크의 마지막 작업은 성능 메트릭 로깅하는 것\n","# 각 에포크마다 진행 상태 로깅을 위해 결과를 trnMetrics_g와 valMerics_g에 수집하였음"],"metadata":{"id":"banFJTBre8Qf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .1 logMetrics 함수"],"metadata":{"id":"20YrVaQvf0Fs"}},{"cell_type":"code","source":["# logMetrics 함수의 시그니처\n","# training.py:251\n","def logMetrics(\n","        self,\n","        epoch_ndx,\n","        mode_str,\n","        metrics_t,\n","        classificationThreshold=0.5,\n","):"],"metadata":{"id":"d3vKanntf2VI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# epoch_ndx는 결과를 로깅할 때 표시하기 위한 용도\n","# mode_str 인자는 메트릭이 훈련용인지 검증용인지 표시\n","# 훈련이면 trnMetrics_t, 검증이면 valMetrics_t을 metrics_t 파라미터로 전달\n","# 두 입력모두 computeBatchLoss를 통해 만들어진 부동소수점 데이터 텐서이며 doTraining이나 doBalidation으로부터 반환 직전에 CPU 영역으로 전송됨\n","# 둘 다 세 개의 행과 샘플 수 만큼의 열 가짐\n","# 세 개 행은 다음의 상수와 동일"],"metadata":{"id":"WnY8G_VfhDas"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:26\n","METRICS_LABEL_NDX=0\n","METRICS_PRED_NDX=1\n","METRICS_LOSS_NDX=2\n","METRICS_SIZE = 3"],"metadata":{"id":"2btYyuKrh4rg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 결절 샘플 또는 비결절 샘플에 대해서만 메트릭 제한하는 마스크 제작하고 클래스별 총 샘플 수와 잘 분류된 샘플의 수 세기\n","# training.py:264\n","negLabel_mask = metrics_t[METRICS_LABEL_NDX] <= classificationThreshold\n","negPred_mask = metrics_t[METRICS_PRED_NDX] <= classificationThreshold\n","\n","posLabel_mask = ~negLabel_mask\n","posPred_mask = ~negPred_mask"],"metadata":{"id":"UfGKIGv6mKSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 결절의 상태 레이블은 True 혹은 False이므로 metrics_t[METRICS_LABEL_NDX]에 저장된 값은 {0.0, 1.0} 범위에 속함\n","# 기본값 0.5로 설정한 classificationThreshold와 비교해 이진값 배열을 얻게 되면 True는 비결절(음성)인 경우의 레이블에 해당\n","# negPred_mask 만들기 위한 비교도 수행함\n","# METRICS_PRED_NDX 값은 모델이 만든 양의 예측값이며 0.0 ~ 1.0인 부동소수점 값\n","# 비교 방식은 동일하지만 실젯값이 0.5에 가까워질 수 있음"],"metadata":{"id":"WhUddTysmsaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 레이블별 통계를 계산하기 위해 마스크를 사용하고 metrics_dict에 결과 저장\n","# training.py:270\n","neg_count = int(negLabel_mask.sum())\n","pos_count = int(posLabel_mask.sum())\n","\n","neg_correct = int((negLabel_mask & negPred_mask).sum())\n","pos_correct = int((posLabel_mask & posPred_mask).sum())\n","\n","metrics_dict = {}\n","metrics_dict['loss/all'] = \\\n","    metrics_t[METRICS_LOSS_NDX].mean()\n","metrics_dict['loss/neg'] = \\\n","    metrics_t[METRICS_LOSS_NDX, negLabel_mask].mean()\n","metrics_dict['loss/pos'] = \\\n","    metrics_t[METRICS_LOSS_NDX, posLabel_mask].mean()\n","\n","metrics_dict['correct/all'] = (pos_correct + neg_correct) \\\n","    / np.float32(metrics_t.shape[1]) * 100\n","metrics_dict['correct/neg'] = neg_correct / np.float32(neg_count) * 100\n","metrics_dict['correct/pos'] = pos_correct / np.float32(pos_count) * 100"],"metadata":{"id":"ibaWS1jOoUFl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 에포크 전체에 대한 평균 손실값 계산\n","# 손실값은 훈련 중 최소화되고 있는 단일값이므로 추적할 필요 있음\n","# negLabel_mask 사용해 음성으로 레이블 된 샘플에 대해서만 손실값의 평균 구하도록 제한하고 posLabel_mask를 사용해 양성에 대한 손실값도 계산\n","# 이처럼 클래스별 계산을 해두면 특정 클래스가 다른 클래스보다 분류하기 어려운 경우를 추적하여 개선하기 좋음"],"metadata":{"id":"qd176Y6vpIOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 마지막으로 전체 샘플 중 얼마나 정확하게 맞추었는지와 각 레이블별 정확도를 계산\n","# 손실값과 마찬가지로, 이 값들은 개선을 위해 어디에 노력을 기울여야 할지 안내하는 역할\n","# 계산 끝나면, 세 번의 log.info 호출을 통해 결과 로깅"],"metadata":{"id":"drW3JHiPqPZ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:289\n","log.info(\n","    (\"E{} {:8} {loss/all:.4f} loss, \"\n","         + \"{correct/all:-5.1f}% correct, \"\n","    ).format(\n","        epoch_ndx,\n","        mode_str,\n","        **metrics_dict,\n","    )\n",")\n","log.info(\n","    (\"E{} {:8} {loss/neg:.4f} loss, \"\n","         + \"{correct/neg:-5.1f}% correct ({neg_correct:} of {neg_count:})\"\n","    ).format(\n","        epoch_ndx,\n","        mode_str + '_neg',\n","        neg_correct=neg_correct,\n","        neg_count=neg_count,\n","        **metrics_dict,\n","    )\n",")\n","log.info(\n","    (\"E{} {:8} {loss/pos:.4f} loss, \"\n","        + \"{correct/pos:-5.1f}% correct ({pos_correct:} of {pos_count:})\"\n","    ).format(\n","        epoch_ndx,\n","        mode_str + '_pos',\n","        pos_correct=pos_correct,\n","        pos_count=pos_count,\n","        **metrics_dict,\n","    )\n",")"],"metadata":{"id":"PeGbP-0Mqn1i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 첫 번째 로그는 모든 샘플에 대해 계산하므로 /all로 태그되었고, 음성은 /neg, 양성은 /pos로 태그됨"],"metadata":{"id":"79E6RaW7rTSV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7절 - 훈련 스크립트 실행"],"metadata":{"id":"s_rQyP-aribx"}},{"cell_type":"code","source":["# 초기화 수행 후 모델 훈련시켜 잘 훈련되고 있는지 통계값 출력할 것\n","# 스크립트는 메인 코드가 들어 있는 디렉토리에서 실행\n","# 디렉토리 아래에 하위 디렉토리가 있어야 함\n","# 사용하는 python 환경은 requirements.txt에 명시한 모든 라이브러리 설치된 상태여야 함\n","$ python -m p2ch11.training"],"metadata":{"id":"GzE58SBurlcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 애플리케이션 실행시켜주는 주피터 노트북을 우리가 제공한다는 사실도 기억\n","run('p2ch11.prepcache.LunaPrepCacheApp')\n","run('p2ch11.training.LunaTrainingApp', '--epochs=1')"],"metadata":{"id":"Pv7IWXQXsemg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련이 시작되면 예상대로 가용한 컴퓨팅 자원을 사용하는지 확인할 필요 있음\n","# 병목 현상이 데이터 로딩 때문인지 연산 때문인지를 구분하려면 스크립트가 실행되어 훈련을 시작할 때까지 잠시 기다린 후 top과 nvidia-smi로 점검\n","# 만일 8개의 파이썬 워커 프로세스가 80% 이상의 CPU 사용한다면 캐시가 필요한 상황\n","# 만일 nvidia-smi에서 GPU-Util이 80% 이상이면 GPU는 풀 가둥인 것임"],"metadata":{"id":"xdDo0C_rs4nV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 여러 에포크를 최대한 빨리 끝내기 위해 가능한 한 많은 컴퓨팅 파워를 사용해야 함\n","# 단일 1080 Ti로 에포크 하나 끝내는 데 15분이 안 걸림\n","# 모델이 상대적으로 단순해 CPU가 병목이 될 만큼 전처리를 위해 많은 CPU 자원을 사용하지 않음\n","# 좀 더 심층 모델을 다룬다면 각 배치를 처리하는데 많은 시간이 걸릴 것이고, 다음 배치 입력이 준비되지 않아 GPU가 할일 없는 상황이 발생하지 않도록 CPU가 처리해야 할 일의 양도 늘어남"],"metadata":{"id":"-1-JPFbkuXLG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .1 훈련에 필요한 데이터"],"metadata":{"id":"98dhm_K3u-F-"}},{"cell_type":"code","source":["# 샘플 수가 적다면 전체 데이터 사용하고 있는지 점검할 필요 있음\n","# data-unversioned/part2/luna 디렉토리의 기본 디렉토리 구조 확인\n","# 각 시리즈 UID에 대해 .mhd파일과 .raw파일이 하나씩 있는지 확인\n","# 파일 수 정확한지 비교\n","# 다 정확한데 잘 동작하지 않는다면 매닝 라이브북(Manning LiveBook) 사이트에 질문"],"metadata":{"id":"5oNK-DcZu9mh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .2 막간을 활용해 enumerateWithEstimate 함수 알아보기"],"metadata":{"id":"RZcVx7NX2hE1"}},{"cell_type":"code","source":["# util.py:143\n","def enumerateWithEstimate(\n","        iter,\n","        desc_str,\n","        start_ndx=0,\n","        print_ndx=4,\n","        backoff=None,\n","        iter_len=None,\n","):\n","    for (current_ndx, item) in enumerate(iter):\n","        yield (current_ndx, item)"],"metadata":{"id":"S-H9LGmZ3_0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# enumerateWithEstimate 함수 사용법과 결과\n","for i, _ in enumerateWithEstimate(list(range(234)), \"sleeping\"):"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"F78Htt2X2gif","executionInfo":{"status":"error","timestamp":1707801116119,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태윤","userId":"12351183305385272389"}},"outputId":"57e8dcfa-634f-4dc4-9152-c979d915c9df"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"incomplete input (<ipython-input-25-84af89ae6784>, line 2)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-84af89ae6784>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for i, _ in enumerateWithEstimate(list(range(234)), \"sleeping\"):\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"]}]},{"cell_type":"code","source":["# enumerateWithEstimate의 동작은 enumerate와 거의 동일(리턴 값이 다름)"],"metadata":{"id":"7PNVD7wz3g94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 딥러닝 프로젝트는 결국 시간 싸움\n","# 언제 작업이 끝날지를 안다면 시간을 효율적으로 사용 가느아며 뭔가 제대로 동작하지 않을 때(또는 접근 방법이 잘못됐을 때) 완료까지 예상보다 훨씬 오래 걸리는 것에서 힌트를 얻어 문제 파악 가능함"],"metadata":{"id":"PDvAyG984aYP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8절 - 모델 평가: 정확도 99.7%라면 잘 끝난 것일까?"],"metadata":{"id":"Paw47aq74zzI"}},{"cell_type":"code","source":["# 훈련 결과를 확인하니 문제가 발생함\n","# 결과를 쉽게 이해할 수 있도록 도구 업그레이드 -> 얻은 메트릭으로 그래프 그리기"],"metadata":{"id":"9-KAKKNh4wmx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 9절 - 텐서보드로 훈련 관련 메트릭를 그려보기"],"metadata":{"id":"PKDZMm306E6R"}},{"cell_type":"code","source":["# 훈련 루프에서 만들어진 훈련 메트릭을 그래프로 만들기 위해 텐서보드 사용\n","# 전체적인 추세 확인 가능\n","# 텐서보드로 메트릭 시각화하면 해당 값이 메트릭의 추세를 따르는지, 이상값인지 구분하기 훨씬 쉬워짐"],"metadata":{"id":"y7LsEHP86HWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 텐서보드는 훌륭하며 파이토치 API로 데이터를 연결해서 빠르고 쉽게 표시할 수 있음"],"metadata":{"id":"loZX6wtQ6mjR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .1 텐서보드 실행"],"metadata":{"id":"Kp97oMcP65rL"}},{"cell_type":"code","source":["# 기본값으로 훈련 스크립트는 메트릭 데이터를 runs/ 하위 디렉토리에 써내려 감"],"metadata":{"id":"D7301ugz67V0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tensorboard 프로그램은 tensorflow 파이썬 패키지를 설치하면 얻을 수 있음\n","# 텐서보드가 사용할 데이터는 별도 폴더로 분리해 놓으면 좋음"],"metadata":{"id":"VZSCLaIm7MHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scalars 탭에서 왼쪽 메뉴는 데스플레이 옵션과 현재 실행 중인 리스트가 보임\n","# 스무딩 옵션은 데이터에 노이즈 많은 경우 유용하며 적용 정도를 선택해 전체 추세를 부드럽게 조절 가능\n","# 훈련 스크립트 실행한 만큼 실행 아이템이 보이고 선택할 수 있음"],"metadata":{"id":"LtGMSdK17e4v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 특정 실행 아이템을 완전히 지우면 텐서보드는 해당 아이템을 디스크에서 삭제함\n","# 잘못 실행됐거나 오류가 나서 수렴하지 않는 등 필요 없는 경우에 지우면 됨\n","# 실행 횟수는 상당히 빠르게 늘어나므로 자주 확인하고 삭제하거나 이름을 알맞게 바꾸고 중요 결과는 특정 디렉토리에 옳겨서 실수로 지우지 않게 함"],"metadata":{"id":"3o15qpFV8Sg2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### .2 메트릭 로깅 함수가 텐서보드를 지원하도록 만들기"],"metadata":{"id":"_VMtnvAK84sK"}},{"cell_type":"code","source":["# 텐서보드가 읽을 수 있는 포맷으로 데이터 저장하려면 torch.utils.tensorboard 모듈 사용해 빠르고 쉽게 메트릭 저장\n","# 텐서보드는 넘파이 배열과 텐서를 지원하므로 텐서 사용"],"metadata":{"id":"n46TLfyn84T4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 먼저 torch.utils.tensorboard에서 임포트 하는 SummaryWriter 객체 생성\n","# 전달할 파라미터는 runs/p2ch11/2020-01-01_12.55.27-trn-dlwpt 같은 것을 초기화할 때 필요한 log_dir 뿐\n","# dlwpt가 정보 제공하도록 변경하기 위해 훈련 스크립트에 주석 인자 더할 수도 있음"],"metadata":{"id":"ionvvOI8A2YK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 쓰기 객체를 훈련 실행 결과와 검증 실행 결과에 사용하도록 두 개 만들기\n","# 쓰기 객체는 모든 에포크에서 재사용\n","# SummaryWriter 클래스 초기화하면 log_dir 디렉토리도 만들어짐\n","# 디텍토리는 텐서보드에 나타나며, 데이터가 만들어지기도 전에 훈련 스크립트 수행이 실패하면 UI가 실행 아이템으로 어지럽혀짐\n","# 너무 많은 빈 UI 실행 아이템이 생기지 않게 데이터가 쓸 만한 단계까지 실행되었을 때 SummaryWriter 객체를 초기화하면 됨\n","# initTensorBoardWriter() 함수는 logMetrics()에서 호출함"],"metadata":{"id":"pyz-mzARBWjK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:127\n","def initTensorboardWriters(self):\n","    if self.trn_writer is None:\n","        log_dir = os.path.join('runs', self.cli_args.tb_prefix, self.time_str)\n","\n","        self.trn_writer = SummaryWriter(\n","            log_dir=log_dir + '-trn_cls-' + self.cli_args.comment)\n","        self.val_writer = SummaryWriter(\n","            log_dir=log_dir + '-val_cls-' + self.cli_args.comment)"],"metadata":{"id":"2BhIVelXCOm9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 루프는 최초에 랜덤하게 초기화된 상태로 실행되므로 첫 에포크의 실행값은 이상하므로 첫 배치에 대한 메트릭 저장하면 결국 값을 왜곡시킴\n","# 텐서보드는 스무딩을 통해 조금이라도 도움되도록 이런 노이즈 줄이는 기능 제공함"],"metadata":{"id":"g8TgPpUYCZNs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 스칼라값 기록은 직관적임\n","# 이미 만든 metrics_dict의 키/값을 writer.add_scalar 메소드에 전달"],"metadata":{"id":"105fF6V6C3ZE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch.utils.tensorboard.SummaryWriter 클래스의 add_scalar 메소드 시그니처\n","def add_scalar(self, tag, scalar_value, global_step=None, walltime=None):\n","    # ..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"A13Z9biWKWBZ","executionInfo":{"status":"error","timestamp":1707805919849,"user_tz":-540,"elapsed":318,"user":{"displayName":"김태윤","userId":"12351183305385272389"}},"outputId":"f752944f-8eea-409a-b85a-86d52166581c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"incomplete input (<ipython-input-38-9607465055b7>, line 3)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-9607465055b7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    # ...\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"]}]},{"cell_type":"code","source":["# tag 파라미터는 텐서보드의 어떤 그래프에 값이 들어가는지를 알려주며 scalar_value 파라미터는 데이터 포인트의 Y축 값을 의미하며 global_step 파라미터는 X축 값으로 동작\n","# doTraining 함수 안에서 totalTrainingSamples_count 변수를 업데이트했던 것을 상기\n","# 이 변수를 global_step 파라미터로 텐서보드에 넘겨 그래프의 X축으로 사용"],"metadata":{"id":"i3h4rnlZKkY6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training.py:323\n","for key, value in metrics_dict.items():\n","    writer.add_scalar(key, value, self.totalTrainingSamples_count)"],"metadata":{"id":"Vb6h-l0uLfRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss/all처럼 키에 /가 들어가면 텐서보드는 / 전까지의 문자열을 잘라 그룹으로 만듦"],"metadata":{"id":"FuCpnhdwLsU3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10절 - 모델이 결절 탐지를 학습하지 못하는 이유"],"metadata":{"id":"5sf8x2--L6O6"}},{"cell_type":"code","source":["# 에포크 증가에 따라 손실값이 일정한 추세를 보이고 결과는 재현 가능하므로 학습하고 있는 것은 명확\n","# 모델에게 기대하는 학습과 실제 모델 학습에는 괴리가 있음"],"metadata":{"id":"7JPRM-b3L5sV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 현재 모델은 모든 질문에 거짓이라고 답하는 단순한 방식으로 동작"],"metadata":{"id":"3TJVu93zMNNU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련셋이나 검증셋에 대해 손실값이 줄어들고 있음\n","# 문제에 대한 추적할 수 있는 값을 가지고 있으므로 희망이 있고 다음 장에서의 과제임"],"metadata":{"id":"pr7O43CEMkWq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 11절 - 결론"],"metadata":{"id":"uMGrnlC8MyCs"}},{"cell_type":"code","source":["# 이제 이전 장에서 만들었던 데이터를 읽어 훈련 루프를 실행하는 모델 존재\n","# 메트릭은 콘솔에 로깅 결과로 나오며 시작적인 그래프 보여줌\n","# 결과는 쓸 만하지 않아 진행 상황을 추적하기 위한 메트릭을 더 개선하여 모델이 합리적인 결과 내려면 어디를 바꿔야 할지 알려주도록 만들 예정"],"metadata":{"id":"E6ahFqJcMz4R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 12절 - 연습 문제"],"metadata":{"id":"Ab8ki3KTNKa0"}},{"cell_type":"code","source":["# 1. DataLoader 인스턴스 내에 래핑한 LunaDataset 인스턴스를 순회하는 프로그램을 만들어라. 순회할 때 걸리는 시간도 알 수 있게 만들어서 10장의 연습 문제와 시간을 비교해보자. 스크립트를 실행할 때 캐시 상태를 인지하기 바란다.\n","#   a. num_worker=를 0, 1, 2로 바꿀 때 어떤 차이가 발생하는가?\n","#   b. 메모리가 모자라지 않는 선에서 최대로 끌어올릴 수 있는 batch_size=와 num_workers=는 얼마인가"],"metadata":{"id":"-Khme4pYNMqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. noduleInfo_list의 정렬 순서를 반대로 해보자. 이렇게 바꾸면 훈련의 첫 에포크 후에 동작 방식에서 어떤 차이가 발생하는가?"],"metadata":{"id":"xRLSvRqZNshO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. logMetrics를 바꿔서 텐서보드가 사용하는 실행 아이템 이름과 키를 변경해보자.\n","#   a. writer.add_scalar로 전달되는 키 값에 처음으로 나타나는 슬래시 문자 위치를 바꿔보자.\n","#   b. 동일한 쓰기 객체를 사용해서 훈련과 검증에 대해 돌려본 후 키 이름에 trn이나 val 문자열을 덧붙여보자.\n","#   c. 로그 디렉토리와 키 값을 원하는 대로 바꿔보자."],"metadata":{"id":"ExVv2S0HN167"},"execution_count":null,"outputs":[]}]}