2
~~~~

3
~~~~

4
~~~~

5
~~~~

6
~~~~

7
~~~~

8
2부 프로젝트는 명령행 애플리케이션입니다
그림은 아나콘다 가상환경입니다
명령행 애플리케이션은 이 그림이나 cmd처럼 작동하는 방식을 뜻합니다

9
이러한 애플리케이션은 클래스를 통해 구현하고 필요할 때 인스턴스로 만들어서 실행할 것입니다
왼쪽 그림은 dsets.py 코드이고 오른쪽은 8장에서 사용한 신경망 코드입니다
8장에서 사용한 것처럼 클래스를 만들고 인스턴스에 클래스를 받아 사용하는 방식을 취할 것입니다

10
~~~~

11
모델을 훈련시키기 전에 선행되는 초기화 작업이 있습니다
~~~~

12
모델 및 옵티마이저 초기화 코드입니다
self.use_cuda 값이 True이면 모델 파라미터를 GPU로 옮겨 대량의 연산에 GPU 사용하도록 설정합니다
옵티마이저 구성 전에 설정해야 옵티마이저가 GPU에 복사된 파라미터를 사용할 수 있습니다
모멘텀 SGD 옵티마이저를 사용하는데 SGD와 설정된 파라미터 값은 학습에 안전한 값들 입니다
이러한 파라미터 값으로는 원하는 수준의 학습이 되지 않는 경우 값을 체계적으로 바꿔가며 찾을 수 있습니다

13
~~~~

14
배치 구현은 DataLoader 클래스를 이용하여 할 수 있습니다
밀도 차원까지 구현된 LunaDataset 클래스를 데이터 로더에 연결하는 코드입니다
검증셋에 경우에는 isValSet_bool=True로 사용합니다
파이토치의 데이터 로딩 기능 사용하면 GPU계산과 데이터로딩을 동시에 진행하여 프로젝트를 빠르게 실행할 수 있습니다

15
~~~~

16
일반적인 분류 모델의 구조는 테일, 백본, 헤드로 구성됩니다
~~~

17
LUNA 모델 아키텍처에서는 ~~~~

18
백본에 사용되는 블록 코드입니다

19
전체 모델의 코드입니다

20
헤드는 입력으로 3차원 텐서를 받지만 선형 계산을 해야 되므로 view()함수를 통해 평탄화시켜서 진행합니다

21
중간값이나 기울기가 이유없이 작아지거나 커지지 않도록 신경망 가중치를 초기화 해줍니다
구체적인 내용은 넘어가겠습니다

22
~~~~

23
모델 훈련 코드입니다
훈련 중 trnMetrics_g 텐서가 클래스 단위 메트릭을 수집합니다
모델이 각 샘플에 대해 computeBatchLoss함수부터 logMetrics 함수까지 어떻게 동작했는지 알려주는 것이 목적입니다

24
~~~~

25
기존과는 다르게 손실값이 들어있는 텐서를 샘플마다 얻습니다
이로써 개별 손실값을 추척할 수 있고 원하는 방식으로 병합할 수 있습니다
반환은 샘플별 손실 평균을 하여 배치 단위 손실과 동일한 값을 반환합니다

26
모든 훈련 및 검증 샘플에 대해 레이블, 예측 결과, 손실값을 기록하여 모델 동작 조사에 사용할 정보 확보합니다

27
검증 루프 코드입니다
self.model.eval()을 이용하여 훈련 때 사용하는 기능을 끕니다
with torch.no_grad()로 신경망 가중치도 조정하지 않습니다
따라서 배치의 전체 손실값을 사용하지는 않지만 valMetrics_g에 메트릭은 저장됩니다

28
~~~~

29
~~~~

30
Epoch_ndx는 결과 로깅 시 표시하기 위한 용도이고
Mode_str는 메트릭이 훈련용인지 검증용인지 표시하는 인자입니다
Metrics 파라미터로 훈련이나 검증 데이터 전달됩니다.
훈련 및 검증 데이터는 세 개의 행과 샘플 수 만큼의 열을 가짐(26p 위 3줄 보면 파악됨)

31
결절 혹은 비결절에 대해 메트릭을 제한하는 마스크를 구성합니다
classificationThreshold=0.5보다 작으면 음성 마스크에 True 넣고 음성 마스크 True False 바꾼 값을 양성 마스크에 넣어서 마스크를 제작합니다

32
음성 및 양성 마스크에 대한 개수를 구하고 각각 레이블과 예측이 맞은 개수를 구합니다
에포크 전체에 대한 평균 손실값 계산하고 음성 및 양성으로 레이블된 샘플에 대해서 각각의 손실값 평균 계산합니다

33
각 레이블별로 정확도를 계산하여 결과를 띄웁니다

34
~~~~

35
훈련을 실행하는 코드입니다
위는 파이썬 환경에서 실행하는 코드이고 아래는 주피터 노트북에서 실행하는 코드입니다

36
~~~~

37
~~~~

38
텐서보드 결과 이미지가 없는 관계로 넘어가겠습니다
각자 책보면 이해 가능할 것입니다

39
결절 탐지를 학습하지 못하는 이유는 거짓인 데이터가 참인 데이터에 비해 너무 많아 전부 거짓으로 답해도 높은 결과를 얻기 때문입니다